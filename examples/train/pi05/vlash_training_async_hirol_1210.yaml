# VLASH Training for HIROL (pi0.5, q2cq mapping)

policy:
  type: pi05
  pretrained_path: /data/model/pi05_base
  push_to_hub: false
  dtype: bfloat16
  device: cuda
  state_cond: true

dataset:
  repo_id: left_fr3_ip_338ep_q2cq
  root: /data/fr3_lerobot/left_fr3_ip_338ep_q2cq
  video_backend: torchcodec

output_dir: /data/ckpts/left_fr3_ip_338ep_q2cq_pi05_vlash
job_name: left_fr3_ip_338ep_q2cq_pi05_vlash
batch_size: 8
steps: 50000
num_workers: 12
seed: 1000

use_policy_training_preset: false

optimizer:
  type: adamw
  lr: 5.0e-5
  betas: [0.9, 0.95]
  weight_decay: 1.0e-10

# Learning rate scheduler
scheduler:
  type: cosine_decay_with_warmup
  num_warmup_steps: 1000
  peak_lr: 5.0e-5
  decay_lr: 2.5e-6
  num_decay_steps: 50000

save_checkpoint: true
save_freq: 10000
log_freq: 500
eval_freq: 500

wandb:
  enable: true
  disable_artifact: true
  project: vlash
  entity: null
# Enable random delay for async-friendlier policies if desired
max_delay_steps: 8
